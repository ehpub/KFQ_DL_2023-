{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMZVk7G4g0k8r4fvQwKBHA7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehpub/KFQ_DL_2023-/blob/main/2023_kfq_%EB%94%A5%EB%9F%AC%EB%8B%9D_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 교재: https://www.gilbut.co.kr/book/view?bookcode=BN003496"
      ],
      "metadata": {
        "id": "l76_ND9MYaO5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DkVAoB3nYY-g"
      },
      "outputs": [],
      "source": [
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BzCxsn4QnYgr",
        "outputId": "b13a0c62-6667-483c-8be8-0b0216ff3ba2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src = \"aidfadf#$5C*4jc*#Jkei!\"\n",
        "\"\".join(char for char in src if char not in string.punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1s1nproHnjq5",
        "outputId": "25c5018c-8ec1-467b-c5a6-9e01b725c726"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aidfadf5C4jcJkei'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vectorizer:\n",
        "  def stardardize(self,text):\n",
        "    text = text.lower()\n",
        "    return \"\".join(char for char in text if char not in string.punctuation)\n",
        "  def tokenize(self,text):\n",
        "    return text.split()\n",
        "  def make_vocabulary(self,dataset):\n",
        "    self.vocabulary = {\"\":0,\n",
        "                       \"[UNK]\":1}\n",
        "    for text in dataset:\n",
        "      text = self.stardardize(text)\n",
        "      tokens =self.tokenize(text)\n",
        "      for token in tokens:\n",
        "        if token not in self.vocabulary:\n",
        "          self.vocabulary[token] = len(self.vocabulary)\n",
        "      self.inverse_vocabulary = dict(\n",
        "          (v,k) for k,v in self.vocabulary.items()\n",
        "      )\n",
        "  def encode(self,text):\n",
        "    text = self.stardardize(text)\n",
        "    tokens =self.tokenize(text)\n",
        "    return [self.vocabulary.get(token,1)  for token in tokens ]\n",
        "  def decode(self,int_sequence):\n",
        "    return \" \".join(self.inverse_vocabulary.get(i,\"[UNK]\") for i in int_sequence)\n",
        "\n"
      ],
      "metadata": {
        "id": "fQW20RwtnIyT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect = Vectorizer()\n",
        "data = [\"I am a boy.\",\n",
        " \"You are a girl.\",\n",
        " \"show me the money.\"]\n",
        "vect.make_vocabulary(data)\n",
        "st = vect.stardardize(\"Hello, I am a gir. You are a mimi.\")\n",
        "tks = vect.tokenize(st)\n",
        "for token in tks:\n",
        "  print(vect.vocabulary.get(token,1))\n",
        "wi = [1,4,5,6,9,10,8,7,5,89]\n",
        "re =vect.decode(wi)\n",
        "print(re)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVUjO6JlqR5u",
        "outputId": "8479dacd-99ff-4149-97a9-b59eeb5caadd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "1\n",
            "6\n",
            "7\n",
            "4\n",
            "1\n",
            "[UNK] a boy you show me girl are boy [UNK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "7EatRNZLq0Ra"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv = layers.TextVectorization(output_mode='int')"
      ],
      "metadata": {
        "id": "CQIDdDy-thC7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv.adapt(data) #앞에서 정의한 Vectorizer 클래스의 makevocabulary와 같은 역할"
      ],
      "metadata": {
        "id": "uYKMKAZ5toBf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjiFpgjytt18",
        "outputId": "54d7d205-70dc-4887-8208-182fa5c1f74f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'a',\n",
              " 'you',\n",
              " 'the',\n",
              " 'show',\n",
              " 'money',\n",
              " 'me',\n",
              " 'i',\n",
              " 'girl',\n",
              " 'boy',\n",
              " 'are',\n",
              " 'am']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv(\"Hello, I am a gir. You are a mimi.\") #encode를 수행"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWI1nETpt_6v",
        "outputId": "3bcf86ea-95cc-4575-da30-c3c5a15e99b4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([ 1,  8, 12,  2,  1,  3, 11,  2,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlZV2Nx-uYlb",
        "outputId": "6a87aad6-e573-427e-b98a-cc1c814aebc6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  49.0M      0  0:00:01  0:00:01 --:--:-- 49.0M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "Irw71sjVyc3w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "uZv__HJpzFOz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat aclImdb/train/pos/4077_10.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-foOum_0zVuV",
        "outputId": "46b237b9-67bc-488f-f678-4bce944346e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os ,pathlib, shutil,random"
      ],
      "metadata": {
        "id": "qBMfu_GOzhfX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = pathlib.Path('aclImdb')\n",
        "val_dir = base_dir/\"val\"\n",
        "train_dir = base_dir/\"train\"\n",
        "for category in (\"neg\",\"pos\"):\n",
        "  os.makedirs(val_dir/category)\n",
        "  files = os.listdir(train_dir/category)\n",
        "  random.Random(1337).shuffle(files)\n",
        "  num_val_samples = int(0.2*len(files))\n",
        "  val_files = files[:num_val_samples]\n",
        "  for fname in val_files:\n",
        "    shutil.move(train_dir/category/fname,\n",
        "                val_dir/category/fname)"
      ],
      "metadata": {
        "id": "K-MR3cmPzzz_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "GwUWSuCW0_0n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = keras.utils.text_dataset_from_directory('aclImdb/train',\n",
        "                                                   batch_size=32)\n",
        "val_ds = keras.utils.text_dataset_from_directory('aclImdb/val',\n",
        "                                                   batch_size=32)\n",
        "test_ds = keras.utils.text_dataset_from_directory('aclImdb/test',\n",
        "                                                   batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ItswDKd1Ndi",
        "outputId": "1d7b681f-e9b4-4532-b293-f5e1e6c459bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in train_ds:\n",
        "  print(x.shape, y.shape)\n",
        "  print(\"x[0]:\",x[0])\n",
        "  print(\"y[0]:\",y[0])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIwDMXW01ksF",
        "outputId": "ddb2d636-aee1-4615-9282-a64250f953e5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32,) (32,)\n",
            "x[0]: tf.Tensor(b\"I had never seen such an incredible acting job in a motion picture as I did when I saw Daniel Day-Lewis play Christy Brown in My Left Foot. In fact off the scene his role wasn't even over. He played the role of Christy Brown or at least disabled like him all through the filming of the movie and needed surgery because of the damage his superior acting had done to his back. To me that is remarkable and through all the pain he put up with to act that role I believe it is quite true to say he put on the most Oscar worthy performance in history. He was so masterful in this tough a part that I believe no one could have done it better or with more of an impact than him. Although I cannot say it is the greatest movie of all time I can say that how he played this impossible a role and then kept on acting it until it wasn't even acting anymore is without a doubt the greatest feet I will ever seen an actor do. Probably a man too for that matter.\", shape=(), dtype=string)\n",
            "y[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv = layers.TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x,y: x)\n",
        "tv.adapt(text_only_train_ds) #vacabulary 형성"
      ],
      "metadata": {
        "id": "_FGeLIRV1u4k"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in text_only_train_ds:\n",
        "  for text in batch:\n",
        "    print(text)\n",
        "    print(tv(text))\n",
        "    print(tv(text).shape)\n",
        "    break\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr1szG__6PBL",
        "outputId": "eb2df52f-3345-4bc5-82af-47c31f865639"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b\"This is Not a Love Song.<br /><br />My one word summary of this film would be `Excellent'.<br /><br />It probably won't appeal to the mass movie watching public \\xc2\\x96 it's a<br /><br />film that forces you to participate. You observe, think, and question.<br /><br />Comparisons could be made with Deliverance (Topic/Theme) and<br /><br />perhaps with The Blair Witch Project for overall filming style.<br /><br />However this film stands unique against both.<br /><br />The cinematography effects (solarisation, freeze frame, blur etc)<br /><br />have been seen before but they are used most effectively in this<br /><br />film to underpin the natural tension of the story.<br /><br />Acting is raw, menacing and utterly believable.<br /><br />The real theme of the film is about friendship; the title really gives<br /><br />the game away. It's probably not the kind of friendship that most of<br /><br />us have experienced or indeed would want to.<br /><br />It is a love song.\", shape=(), dtype=string)\n",
            "tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "(20000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "binary_1gram_test_ds = test_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")"
      ],
      "metadata": {
        "id": "jV_pC1ua6v4j"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in binary_1gram_train_ds:\n",
        "  print(x.shape, y.shape)\n",
        "  print(\"x[0]:\",x[0])\n",
        "  print(\"y[0]:\",y[0])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioSL-2YY5ZUK",
        "outputId": "9c30259f-0c11-43b5-ecdb-ab837a7c238e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 20000) (32,)\n",
            "x[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
            "y[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(max_tokens=20000,hidden_dim=16):\n",
        "  inputs = keras.Input(shape=(max_tokens,))\n",
        "  x = layers.Dense(hidden_dim,activation='relu')(inputs)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "  model = keras.Model(inputs,outputs)\n",
        "  model.compile(loss=keras.losses.binary_crossentropy,\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "hGAr5_IZ7tcF"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOsDhTHi8gIM",
        "outputId": "eaad704b-be28-41e6-88eb-fe08560323e8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcp = keras.callbacks.ModelCheckpoint('binary_1gram.keras',\n",
        "                                      save_best_only=True)\n",
        "model.fit(binary_1gram_train_ds.cache(),\n",
        "          validation_data=binary_1gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=[mcp])\n",
        "model = keras.models.load_model('binary_1gram.keras')\n",
        "model.evaluate(binary_1gram_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMFexkmZ8oNX",
        "outputId": "90d51178-e4d5-4c09-b521-952c695ac91d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.4162 - accuracy: 0.8257 - val_loss: 0.3005 - val_accuracy: 0.8812\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2804 - accuracy: 0.8982 - val_loss: 0.2989 - val_accuracy: 0.8858\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2453 - accuracy: 0.9146 - val_loss: 0.3045 - val_accuracy: 0.8850\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2234 - accuracy: 0.9240 - val_loss: 0.3312 - val_accuracy: 0.8788\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2204 - accuracy: 0.9276 - val_loss: 0.3292 - val_accuracy: 0.8810\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2103 - accuracy: 0.9305 - val_loss: 0.3550 - val_accuracy: 0.8788\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2056 - accuracy: 0.9340 - val_loss: 0.3581 - val_accuracy: 0.8782\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2010 - accuracy: 0.9345 - val_loss: 0.3690 - val_accuracy: 0.8788\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1962 - accuracy: 0.9374 - val_loss: 0.3832 - val_accuracy: 0.8708\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1988 - accuracy: 0.9356 - val_loss: 0.3926 - val_accuracy: 0.8702\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 0.2934 - accuracy: 0.8814\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2933864891529083, 0.8814399838447571]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv = layers.TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x,y: x)\n",
        "tv.adapt(text_only_train_ds) #vacabulary 형성"
      ],
      "metadata": {
        "id": "ku51Vva19a_2"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")"
      ],
      "metadata": {
        "id": "Xtb8MeThCm3u"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "mcp = keras.callbacks.ModelCheckpoint('binary_2gram.keras',\n",
        "                                      save_best_only=True)\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "          validation_data=binary_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=[mcp])\n",
        "model = keras.models.load_model('binary_2gram.keras')\n",
        "model.evaluate(binary_2gram_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eenh1FsHCwbw",
        "outputId": "d0d1281d-8c1d-49ca-a11d-fdf52895c1d9"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 7s 10ms/step - loss: 0.3709 - accuracy: 0.8441 - val_loss: 0.2871 - val_accuracy: 0.8858\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2334 - accuracy: 0.9177 - val_loss: 0.2782 - val_accuracy: 0.9008\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2046 - accuracy: 0.9333 - val_loss: 0.2997 - val_accuracy: 0.9002\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1811 - accuracy: 0.9430 - val_loss: 0.3165 - val_accuracy: 0.9018\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 2s 4ms/step - loss: 0.1802 - accuracy: 0.9480 - val_loss: 0.3275 - val_accuracy: 0.8976\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1700 - accuracy: 0.9522 - val_loss: 0.3641 - val_accuracy: 0.8982\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1586 - accuracy: 0.9528 - val_loss: 0.3736 - val_accuracy: 0.9002\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1632 - accuracy: 0.9534 - val_loss: 0.3873 - val_accuracy: 0.8964\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1692 - accuracy: 0.9556 - val_loss: 0.3807 - val_accuracy: 0.8908\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1553 - accuracy: 0.9563 - val_loss: 0.4021 - val_accuracy: 0.8904\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2728 - accuracy: 0.9002\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27281391620635986, 0.900160014629364]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv = layers.TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"count\",\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x,y: x)\n",
        "tv.adapt(text_only_train_ds) #vacabulary 형성"
      ],
      "metadata": {
        "id": "z_FmUndfC9gL"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_2gram_train_ds = train_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "count_2gram_val_ds = val_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "count_2gram_test_ds = test_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")"
      ],
      "metadata": {
        "id": "Qj3me4yEDdlR"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "mcp = keras.callbacks.ModelCheckpoint('count_2gram.keras',\n",
        "                                      save_best_only=True)\n",
        "model.fit(count_2gram_train_ds.cache(),\n",
        "          validation_data=count_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=[mcp])\n",
        "model = keras.models.load_model('count_2gram.keras')\n",
        "model.evaluate(count_2gram_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br4owns9Dp3X",
        "outputId": "1622204f-a8b3-4814-fb9e-b37eadd762e6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4508 - accuracy: 0.7955 - val_loss: 0.3099 - val_accuracy: 0.8768\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3036 - accuracy: 0.8737 - val_loss: 0.2786 - val_accuracy: 0.8982\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2662 - accuracy: 0.8942 - val_loss: 0.2891 - val_accuracy: 0.8944\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2427 - accuracy: 0.9068 - val_loss: 0.2943 - val_accuracy: 0.8982\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2300 - accuracy: 0.9122 - val_loss: 0.3247 - val_accuracy: 0.8884\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2248 - accuracy: 0.9137 - val_loss: 0.3190 - val_accuracy: 0.8906\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2135 - accuracy: 0.9180 - val_loss: 0.3456 - val_accuracy: 0.8888\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2131 - accuracy: 0.9190 - val_loss: 0.3523 - val_accuracy: 0.8874\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2073 - accuracy: 0.9204 - val_loss: 0.3579 - val_accuracy: 0.8892\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2073 - accuracy: 0.9228 - val_loss: 0.4005 - val_accuracy: 0.8616\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2679 - accuracy: 0.8980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2678576707839966, 0.8980399966239929]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv = layers.TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"tf_idf\",\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x,y: x)\n",
        "tv.adapt(text_only_train_ds) #vacabulary 형성"
      ],
      "metadata": {
        "id": "gnUzw4l_DzTB"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_2gram_train_ds = train_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "tfidf_2gram_val_ds = val_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "tfidf_2gram_test_ds = test_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")"
      ],
      "metadata": {
        "id": "XG3pDFT4EcXt"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "mcp = keras.callbacks.ModelCheckpoint('tfidf_2gram.keras',\n",
        "                                      save_best_only=True)\n",
        "model.fit(tfidf_2gram_train_ds.cache(),\n",
        "          validation_data=tfidf_2gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=[mcp])\n",
        "model = keras.models.load_model('tfidf_2gram.keras')\n",
        "model.evaluate(tfidf_2gram_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imEJdT2wEia7",
        "outputId": "84e8e84a-ec9c-46e1-d2c3-1cfed8b429f4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4798 - accuracy: 0.7793 - val_loss: 0.4122 - val_accuracy: 0.8490\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3191 - accuracy: 0.8646 - val_loss: 0.2981 - val_accuracy: 0.8926\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2816 - accuracy: 0.8850 - val_loss: 0.3902 - val_accuracy: 0.8502\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2559 - accuracy: 0.8984 - val_loss: 0.3604 - val_accuracy: 0.8892\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2437 - accuracy: 0.9035 - val_loss: 0.3361 - val_accuracy: 0.8914\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2163 - accuracy: 0.9096 - val_loss: 0.3575 - val_accuracy: 0.8906\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2098 - accuracy: 0.9109 - val_loss: 0.3606 - val_accuracy: 0.8870\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2075 - accuracy: 0.9129 - val_loss: 0.3733 - val_accuracy: 0.8908\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1983 - accuracy: 0.9167 - val_loss: 0.4094 - val_accuracy: 0.8886\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1948 - accuracy: 0.9186 - val_loss: 0.3913 - val_accuracy: 0.8846\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2958 - accuracy: 0.8956\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2958030700683594, 0.8955600261688232]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시퀀스"
      ],
      "metadata": {
        "id": "7IXzWr2Ffffg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "LZIoQs-Xk7e-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 600\n",
        "max_tokens= 20000"
      ],
      "metadata": {
        "id": "wgnRJTFOEs8U"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x,y: x)\n",
        "tv.adapt(text_only_train_ds) #vacabulary 형성"
      ],
      "metadata": {
        "id": "_ucq2oC6ftmC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_train_ds = train_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x,y: (tv(x),y),\n",
        "    num_parallel_calls=4\n",
        ")"
      ],
      "metadata": {
        "id": "3-_QsdNtgzu6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "wFjqfTxAiAA1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,),dtype='int64')\n",
        "embedded = tf.one_hot(inputs,depth=max_tokens)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "model = keras.Model(inputs,outputs)\n",
        "model.compile(loss=keras.losses.binary_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wLNkVlZQiXMG"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcp = keras.callbacks.ModelCheckpoint('one_hot_bidir_lstm.keras',\n",
        "                                      save_best_only=True)\n",
        "model.fit(int_train_ds.cache(),\n",
        "          validation_data=int_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=[mcp])\n",
        "model = keras.models.load_model('one_hot_bidir_lstm.keras')\n",
        "model.evaluate(int_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlGjmdo0jSxQ",
        "outputId": "1f397f08-4711-46ca-8408-dfb16ffd69ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,),dtype='int64')\n",
        "embedded = layers.Embedding(input_dim=max_tokens,output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "model = keras.Model(inputs,outputs)\n",
        "model.compile(loss=keras.losses.binary_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "K0omLkiPjmZs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcp = keras.callbacks.ModelCheckpoint('embedding_bidir_lstm.keras',\n",
        "                                      save_best_only=True)\n",
        "model.fit(int_train_ds.cache(),\n",
        "          validation_data=int_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=[mcp])\n",
        "model = keras.models.load_model('embedding_bidir_lstm.keras')\n",
        "model.evaluate(int_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG59nyOmlHFm",
        "outputId": "b78ab260-0b46-4bec-ddd5-1ccf090fe238"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 101s 147ms/step - loss: 0.5265 - accuracy: 0.7377 - val_loss: 0.4455 - val_accuracy: 0.8288\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.3584 - accuracy: 0.8644 - val_loss: 0.4313 - val_accuracy: 0.8460\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.3085 - accuracy: 0.8873 - val_loss: 0.3211 - val_accuracy: 0.8692\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.2371 - accuracy: 0.9197 - val_loss: 0.3609 - val_accuracy: 0.8730\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.2113 - accuracy: 0.9276 - val_loss: 0.3388 - val_accuracy: 0.8672\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.1829 - accuracy: 0.9413 - val_loss: 0.3670 - val_accuracy: 0.8742\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 0.1603 - accuracy: 0.9484 - val_loss: 0.4123 - val_accuracy: 0.8748\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.1395 - accuracy: 0.9563 - val_loss: 0.4327 - val_accuracy: 0.8756\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.1281 - accuracy: 0.9603 - val_loss: 0.3844 - val_accuracy: 0.8766\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 21s 34ms/step - loss: 0.1136 - accuracy: 0.9671 - val_loss: 0.4347 - val_accuracy: 0.8704\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 0.3427 - accuracy: 0.8554\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34273719787597656, 0.8553599715232849]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7nyBoNiTlOm5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}